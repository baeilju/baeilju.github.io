- 참고 : https://man-tae.tistory.com/5

- Server 실행
```
zookeeper-server-start.bat ../../config/zookeeper.properties
kafka-server-start.bat ../../config/server.properties
```

- Topic 생성/조회
```
kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test21041301
kafka-topics.bat --list -zookeeper localhost:2181
```

- 컨슈머, 프로듀서 시작
```
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test21041301
kafka-console-producer.bat --broker-list localhost:9092 --topic test21041301
```


파편화된 데이터 파이프라인의 구조 개선
각각의 애플리케이션을 연결하는게 아니라 중앙집중화
카프카 내부 큐 구조
자료를 보내는 것 프로듀서
받는 것 컨슈머
상용서비스에서는 중앙집중화로 인한 서비스 다운 막기 위해 3대 이상으로 카프카 서버를 분산 운영함
프로듀서에서 받은 데이터는 파일시스템에 저장함
재시작해도 안전하게 데이터 다시 처리 가능

초기 데이터레이크는 데이터를 End to end로 배치로 수집함
배치는 유연하지 못함, 실시간 데이터에 대한 처리 늦음
데이터 히스토리 파악이 어려움
데이터 가공이 지속되면 파편화, 거버넌스를 지키기 어려움

이를 개선하기 위한 람다 아키텍처
배치 레이어 : 배치 데이터를 일정 시간마다 일괄 처리
서빙 레이어 : 사용자가 쓸 수 있게 저장된 공간
스피드 레이어 : 원천 데이터를 실시간 분석하기 위한 공간
카프카 => 스피드 레이어
필요한 경우 서빙 레이어로 보내기도함

레이어가 나뉘는 문제 -> 그래서 등장한게 카파 아키텍처
배치레이어 제거, 모든 데이터를 스피드 레이어에 넣어서 저장

2020년
스트리밍 데이터레이크 제안
데이터가 필요한 모든 고객은 카프카를 참조한다
개선점
자주 사용하지 않는 데이터는 저렴한 오브젝트 스토리지에 저장하고
자주 사용하는 데이터만 브로커로?
콜드 데이터는 오브젝트 스토리지, 핫 데이터는 카프카로


## 카프카 구성요소
파티션 : 데이터(레코드)가 저장되는 공간
레코드 <- 타임스탬프, 메시지 키, 메시지 값, 오프셋
타임스탬프: 레코드 생성시간, 혹은 사용자 지정 가능
메시지 키 : 유용하지만 생략가능
메시지 값 : 실제 데이터
오프셋 : 파티션 내 레코드 별 지정번호, 인덱스 같은 개념

토픽 : 파티션들의 묶음, 데이터베이스의 테이블과 유사함
토픽에 들어간 데이터는 컨슈머가 가져가더라도 삭제되지 않음
브로커가 지울 수 있음
파티션이 많을수록 병렬처리를 늘릴 수 있다
파티션 만큼 컨슈머를 늘릴 수 있다
이미 가지고 있는 파티션을 줄이는 것은 불가능하다

ex) 토픽명 dev.email.json
어디, 무엇, 어떤 데이터

데이터 삭제는 2가지 옵션이 있다
delete
  - retention.ms : 시간에 따른 삭제 옵션
  - retention.bytes : 양에 따른 삭제 옵션
compact : 메시지 키 단위로 이전 데이터 삭제, 스트림 애플리케이션을 만들때 사용한다


브로커 : 카프카를 저장하는 공간
주피터가 받드시 필요함 : 카프카의 메타데이터를 저장함, 토픽의 파티션 위치, 컨슈머 그룹 이름 등
서버 1대에 1개 운영이 바람직. 장애 대응을 위해
프로듀서가 보낸 데이터는 브로커가 있는 서버의 파일시스템에 저장됨
카프카에서는 파티션을 복제해서 여러 서버에 저장
리더 파티션, 팔로워 파티션
여러 브로커 중 한대는 코디네이터 역할을 한다

리더 파티션은 프로듀서와 통신. 한 브로커에 몰려 있다면 재분배 필요

In-Sinc-Replicas
리더 파티션 레코드가 팔로워에 복제가 완료된 상태
리더가 장애나면 팔로워 중 하나가 리더로 승격

컨슈머
컨슈머와 파티션은 1:1 매칭
컨슈머 그룹을 구분해서 동일 파티션에 대한 데이터 처리를 목적별로 분리 수행할 수 있음
컨슈머는 오프셋 커밋을 통해 어디까지 데이터 처리했는지 확인함

멱등성 idempotence
pid, sequence 비교하여 중복되는 데이터는 적재하지 않음
대신 broker 부하 발생

트랜잭션 프로듀서, 컨슈머
여러 레코드를 하나의 단위로 묶어서 처리 -> commit 후 한 데이터 가져감

카프카 스트림즈
생산 -> 소비가 아니라 중간 연산이 필요할 때
소스/스트림/싱크 프로세서

카프카 커넥트
프로듀서와 컨슈머를 반복적으로 만드는 것을 도와줌
pipeline 만들 때 도움


커넥터 : 템플릿


미러메이커2 : 클러스터 간 토픽 복제

카프카와 연동되는 오픈소스(비공식 컴포넌트)
로그에이전트
- 텔레그래프
- 로그스태시
스트림 데이터 프로세싱
- 스파크 스트리밍
- 플링크
모니터링 및 운영
- CMAK
- kafdrop
- 링크드인 버로우 : 컨슈머 랙 측정

브로커 -> JMX -> JMX exporter -> 프로메테우스 -> 그라파나 대시보드

## 카프카 설치 및 실행, 명령어 실습

